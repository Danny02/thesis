\section{Evaluation}
Code formatting is inherently a subjective topic.
This introduces a challenge when evaluating a code formatter.
In this chapter, we will present measurements that we believe show the success of scalafmt.
We do not measure how well software developers perceive scalafmt formatted code.
Instead, we will focus on \emph{performance benchmarks} and \emph{user adoption}.

\subsection{Performance benchmarks}
In this chapter, we describe our test methodology, key metrics and the performance results.

\subsubsection{Setup}
The benchmarks are run on a Macbook Pro (Retina, 15-inch, Mid 2014) laptop with a quad-core 2.5 GHz Intel Core i7 processor, 256 KB L2 cache per core and 6 MB shared L3 cache.
The laptop has 16 GB 1600 MHz DDR3 memory.
The operating system is OS X El Capitan 10.11.5.
We run the benchmarks from the scalafmt commit id \href{https://github.com/olafurpg/scalafmt/tree/aff5e794dae4787b08243f8abb87a3ca4d907e40}{aff5e794} compiled against Scala 2.11.7, running on JVM version 8, update 91.
All benchmarks are run with the OpenJDK Java Microbenchmark Harness (JMH)\autocite{OpenJ38:online}.
Benchmarking on the JVM is notoriously hard, JMH is designed to take into account a variety of parameters that affect performance on the JVM to obtain accurate measurements.
The sbt-jmh\autocite{ktoso84:online} plugin makes it easy to integrate JMH with a Scala project.

\subsubsection{Macro benchmark}
The macro benchmarks is designed to get insight on how scalafmt performs in a continuous integration setup.
We format the entire Scala.js codebase.
The codebase contains ??? source files with combined ??? lines of code.
We believe the Scala.js codebase strikes a fine balance between size and X.
For accurate measurements, we run five iterations of the macro benchmark.
We compare the running time with Scalariform.
The macro benchmark is multi-threaded and takes advantage of all cores on the underlying hardware.

Table~\ref{tab:macro} shows the results from the macro benchmark.
\begin{table}
  \centering
  \caption{Results from macro benchmark.}\label{tab:macro}
  \input{target/macro.tex}
\end{table}
Scalafmt is much slower, which may not be surprising considering since scalafmt's primary goal has always been to produce appealing output.
Scalafmt may try thousands of different formatting layouts to produce an optimal formatting output.
Scalariform's formatting algorithm is linear.
Still, we are quite content with the performance of scalafmt.
This benchmark reveals that scalafmt can format 12.000 lines of code per second.


\subsubsection{Micro benchmark}
The micro benchmark is designed to get insight into how scalafmt performs in an interactive software developer workflow.
For example, it is common to configure a text editor to format source code on every save.
First, we find out how many lines of code are typical in a source file.

We performed a small study to learn the size of a typical source file.
We collected a sample of 3.2 million lines of code.
Table~\ref{tab:macro_sample} shows the distribution of file sizes in our sample.
\begin{table}
  \centering
  \caption{Percentiles of lines of code per file in macro benchmark.}~\label{tab:macro_sample}
  \input{target/file_sizes.tex}
\end{table}
For example, 25th percentile of files have 16 lines of code.
Observe that over 90 percent of all files are rather small, or under 300 lines of code.
Less than one percent of all files contain over 1.000 lines of code.

Using the results from our small study, we choose to run the micro benchmark on select four selected files of varying sizes: small ($\sim$ 50 LOC), medium ($\sim$300 LOC), large ($\sim$1.000 LOC) and extra large ($\sim$4.500 LOC).
To minimize error margins, we run 10 warmup iterations followed by 10 measured iterations.
As in the macro benchmark, we compare the running time with Scalariform.
The micro benchmark is single threaded.

Table~\ref{tab:micro} shows the results from the micro benchmark.
\begin{table}
  \centering
  \caption{Results from micro benchmark.}\label{tab:micro}
  \input{target/micro.tex}
\end{table}
No surprise, scalafmt is a slower than Scalariform again.
In fact, scalafmt seems a lot slower in this benchmark compared to the macro benchmark.
Why is that?
Moreover, is this performance gap acceptable for interactive software development.

To answer the first question, we believe scalafmt performs better in the macro benchmark --- relative to Scalariform --- because macro benchmark is multi-threaded while the micro benchmark is single threaded.
As the measurements show, scalafmt operations are slower.
Hence, the scheduler in the macro benchmark is presumably more efficient at allocating CPU wall time to the scalafmt test runs compared to Scalariform.

Secondly, we believe this performance is usable for most use-cases, but needs improvements to be acceptable for settings such as reformat on save/compile.
We currently don't recommend users to configure text editors to run scalafmt no every file save.
Amazon famously showed that sales decreased by 1 percent for every 100ms increase in page load time\autocite{kohavi2007online}.
We believe similar principles apply to scalafmt, every millisecond counts in the user experience.
Still, we believe with the current performance scalafmt delivers enough benefits to be useful.
As we'll discuss in the following section, our users seem to agree.

\subsection{Adoption}\label{sec:adoption}
Scalafmt has received quite some attention since its release in early March, three months ago.
In this section we present the statistics we believe demonstrate that scalafmt is --- despite its young age --- already proving itself useful for the Scala community.
All data points are as of June 9th, 2016.

\subsubsection{Installations}
Scalafmt has been installed over 6.500 times.
  Table~\ref{tab:installs} shows the installation numbers for each official distribution channel.
  \begin{figure}
    \CenterFloatBoxes
    \begin{floatrow}
      \ffigbox
      {\includegraphics[width=0.4\textwidth,angle=-90]{target/month.eps}}
      {\caption{Installations by month by channel.}\label{fig:installs}}
      \killfloatstyle
      \ttabbox{\input{target/installs.tex} }{
        \caption{Download numbers for scalafmt.}\label{tab:installs}}
    \end{floatrow}
  \end{figure}
IntelliJ is the Jetbrains plugin repository\footnote{
  See \url{https://plugins.jetbrains.com/plugin/8236?pr=}
}.
Data is not available for how many users built scalafmt from source.
The numbers represent absolute download numbers, not unique users.
Observe that v0.2.5 was released 22 days ago, meaning it has been installed 80 times on average per day since its release.
Considering the v0.2.5 installations numbers, it is fair to estimate that scalafmt currently has at least 1.000 users.

Figure~\ref{fig:installs} shows the growth in installations by month.
Observe that growth has doubled with each month.
Github represented proportionally many installs in the first month but only represents a small fraction of installation in May.
Maven installations quadrupled in May, taking the lead from the IntelliJ plugin in April.


\subsubsection{Other}
We present interesting data points from a variety of disparate data sources:

\begin{itemize}
  \item The scalafmt code repository has received contributions from 8 external contributors.
    Several of these contributions added non-trivial features to scalafmt, including
    new configuration flags and extensions to the Router.
  \item 34 unique users, excluding the author, have opened a total of 138 tickets on the scalafmt issue tracker.
  \item The scalafmt Gitter\footnote{See \url{https://gitter.im/olafurpg/scalafmt}} instant messaging channel has 47 members. The channel is used to informally discuss bugs, new features and more.
  \item The user documentation website\footnote{See \url{http://scalafmt.org}} has been visited 5.422 times with an average visit duration of 98 seconds. That makes 138 hours of combined visit time.
\end{itemize}



